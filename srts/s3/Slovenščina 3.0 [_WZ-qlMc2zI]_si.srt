1
00:00:00,000 --> 00:00:17,799
Ok, lepo pozdravljeni vsi skupaj v novej epizodi Ogrodja in lepo pozdravljeni

2
00:00:17,799 --> 00:00:23,400
vsi skupaj tudi na konferenci Make It. Danes snevamo epizodo Ogrodja pred

3
00:00:23,400 --> 00:00:29,400
živo publiko, ampak za to ne bo nič manj zanimiva in nič manj tehnično

4
00:00:29,400 --> 00:00:37,000
površena. Danes imamo eno zanimivo temo, ki smo jo pojmenovali

5
00:00:37,000 --> 00:00:45,799
Slovenščina tri pikanič. To je tema, ki je po sebi v zadnjih parih letih

6
00:00:45,799 --> 00:00:54,799
bomo rekli, ta je postala zelo aktualna in prišli smo nekako, mi vidimo,

7
00:00:54,799 --> 00:01:00,599
da je tudi ideja tega naslove v neko tretjo fazo jezikovnih tehnologij,

8
00:01:00,599 --> 00:01:05,000
pa upamo, da bomo tudi s to debankali. Ampak, če smo začeli sploh

9
00:01:05,000 --> 00:01:10,599
s Slovenščino, pa se je Slovenščina nazivjala kot neka napisana beseda,

10
00:01:10,599 --> 00:01:16,400
kot govorjena beseda, pa smo neki točki zapisali, potem nekako s tehnologijo

11
00:01:16,400 --> 00:01:20,400
smo jo poskušali digitalizirati, pa imamo slovarje, pa imamo prevajalnike

12
00:01:20,400 --> 00:01:27,400
in podobno. Zdaj nekako gremo z tehnologijo, ki je temelina teh

13
00:01:27,400 --> 00:01:32,199
velikih jezikovnih modeljev v neko tretjo dobo Slovenščine in od to

14
00:01:32,199 --> 00:01:39,199
smo pobrali tudi naš naslov. Danes je z nami prof. dr. Marko Bajec

15
00:01:39,199 --> 00:01:45,400
iz FRIA, ki se ukvarja v različnih laboratorijih, različnih projektih

16
00:01:45,400 --> 00:01:51,000
s podobnimi jezikovnimi tehnologijami in upam, da bomo skupaj nekako

17
00:01:51,000 --> 00:01:55,199
raziskali to področje, pa da bomo šli ne samo v površinsko, ampak tudi

18
00:01:55,199 --> 00:02:00,599
mogoče malo globlje v te koncepte. Sem še kaj pozabljen, draž, prednjega.

19
00:02:00,599 --> 00:02:07,000
Ja, dogovorili smo se, da se bomo tikali, tako da ne bomo komu čudno,

20
00:02:07,000 --> 00:02:13,800
ker smo v bistvu, kaj že, enako stari med inženerji, tako ja.

21
00:02:14,800 --> 00:02:19,399
Jaz bi povsem prosil, da se mogoče sam predstaviš, da bomo pravilno

22
00:02:19,399 --> 00:02:22,399
in ostrezno predstavitev ujeli.

23
00:02:22,399 --> 00:02:27,199
Ja, hvala, najprej lepo zdrav vsem v dvorani. Marko Bajec iz fakultete

24
00:02:27,199 --> 00:02:31,199
za žurnalištvo in informatiko, predavam predmete z področja

25
00:02:31,199 --> 00:02:36,199
podatkovnih BAS, kar me tudi sveda druži iz predhodnica te konference,

26
00:02:36,199 --> 00:02:41,399
in pa razvoja informacijskih sistemov in pa tudi tehnologij, ki so povezane

27
00:02:41,399 --> 00:02:47,000
za govor in pa jeziki. Vodim laboratori za podatkovne tehnologije

28
00:02:47,000 --> 00:02:52,199
in zadnje leta se zares veliko ukvarjamo z govornimi in jezikovnimi

29
00:02:52,199 --> 00:02:57,000
tehnologijami in poskušamo spraviti Slovenščino do te mire,

30
00:02:57,000 --> 00:03:03,399
da ne bi digitalno nekje ostala na nekaj točki, kar nam bi v prihodnosti

31
00:03:03,399 --> 00:03:08,600
znalo v resnici zloško dovet, ker danes vemo, da pričakujemo,

32
00:03:08,600 --> 00:03:12,199
da bo večina komunikacije med človekom, stroje med človekom

33
00:03:12,199 --> 00:03:17,600
in pravo govorna in če ne bomo poskrbeli za svoj jezik,

34
00:03:17,600 --> 00:03:22,199
tudi v digitalnem smislu, se nam lahko zelo hitro zgodi,

35
00:03:22,199 --> 00:03:26,399
da bomo zgol razočarano gledali, kakšne rešitve imajo tu inimih,

36
00:03:26,399 --> 00:03:29,800
pa doma za svoj jezik ne moramo imeti.

37
00:03:29,800 --> 00:03:35,800
In zato sem tudi veseljen s prejono, to pa bo bilo, da malo delimo te stvari.

38
00:03:36,000 --> 00:03:42,399
Odlično. Jaz sem hotel odpreti to debato z enim močnim vprašanjem.

39
00:03:42,399 --> 00:03:50,399
In sicer, kako daleč smo tehnološko do koraka, ko bomo lahko,

40
00:03:50,399 --> 00:03:54,000
moram reči tehnologijo, pa bom postavil odprte vprašanje,

41
00:03:54,000 --> 00:03:59,399
jih bomo povedali naše medicinske simptome v Slovenščini

42
00:03:59,399 --> 00:04:05,199
in bomo dobili nazaj diagnozo, ki bi jim mogoče lahko celo zaupali.

43
00:04:05,199 --> 00:04:09,800
A je to preveč močno vprašanje?

44
00:04:09,800 --> 00:04:15,199
Vprašanje je vredno. Odvisno pa zdaj, kakšen bo odgovor.

45
00:04:15,199 --> 00:04:20,399
Najprej ne povem, da jaz vseeno spodem med bolj konzervativne raziskovalce

46
00:04:20,399 --> 00:04:25,600
in znanstvenike in mogoče nisem med tistimi, ki so izjemno

47
00:04:25,600 --> 00:04:32,200
tehnološko navdušeni zelo hitro. Ampak glede na to, da ste večinoma

48
00:04:32,200 --> 00:04:38,600
tehnični danes, tehnično potkovanje, mislim, da mi ni treba zbirati besed.

49
00:04:38,600 --> 00:04:43,000
Zato bom povedal tako, kot dejansko stvari vidim, pa ne bi vsakemu

50
00:04:43,000 --> 00:04:49,399
tako odgovarjal. Jaz mislim, da zagotovo smo že zelo, zelo daleč

51
00:04:49,399 --> 00:04:54,799
in rešitve, ki imajo v zadju velike jezikovne modele, so nam lahko

52
00:04:54,799 --> 00:05:01,000
že izjemno dober pomočnik, asistent. Delamo pa napako,

53
00:05:01,000 --> 00:05:06,600
če jim zaupamo, da se same odločajo. Tako da tudi na področju medicine

54
00:05:06,600 --> 00:05:13,000
je tako. Jaz mislim, da so lahko rešitve, ki jih zdravnik konzultira,

55
00:05:13,000 --> 00:05:18,799
praša, lahko zelo koristne, ker imajo lahko v sebi, v jezikovnih

56
00:05:18,799 --> 00:05:22,600
modelih, pa tudi v drugih modelih. Imajo lahko ogromno nekopičenega

57
00:05:22,600 --> 00:05:28,000
znanja, česar zdravnik nikoli življenje niti prebrati ne more.

58
00:05:28,000 --> 00:05:32,399
In so mu lahko v pomoč, ampak končno odločitev in pa interpretacijo

59
00:05:32,399 --> 00:05:37,799
tega, kar dobi, mora pa vseeno delati človek. Tako da čisto konkretno

60
00:05:37,799 --> 00:05:41,600
pa na vaše vprašanje take rešitve že obstajajo. Vprašanje pa,

61
00:05:41,600 --> 00:05:45,799
koliko jim lahko seveda zaupamo in če jih boste preverjali,

62
00:05:45,799 --> 00:05:50,200
boste videli, da so večinoma vs na koncu v smeru od zdravnikov,

63
00:05:50,200 --> 00:05:52,200
ker je to edinovarno.

64
00:05:53,200 --> 00:06:01,200
Eno izmed mogoče težav velikih jezikovnih modelov je, da smo jih

65
00:06:01,200 --> 00:06:05,600
sicer najprej srečali skozi te četbote, ki so ljudje začeli

66
00:06:05,600 --> 00:06:09,799
videti, da jih lahko vprašajo in odgovarjajo, ampak mogoče

67
00:06:09,799 --> 00:06:14,600
se s tem terminom nekako skrije to dejstvo, da je v njih

68
00:06:14,600 --> 00:06:19,600
zakodiranega veliko znanja. In saj ta priprava znanja,

69
00:06:19,600 --> 00:06:26,200
čiščenje znanja, je to mogoče nek, je to dobra upis teh

70
00:06:26,200 --> 00:06:30,600
tehnologij nasploh, pa TV-tehnologij recimo?

71
00:06:30,600 --> 00:06:36,600
Zagotovo je res, da večina ljudi dojema velike jezikovne modele

72
00:06:36,600 --> 00:06:42,200
skozi četbote, skozi čet GPT in podobne, ki danes so, ki pa so

73
00:06:42,200 --> 00:06:46,200
veliko, veliko več kot samo jezikovni model. Res je, da je temel

74
00:06:46,200 --> 00:06:50,799
v ozadju jezikovni model, ampak tudi, če ste karkoli prebrali o tem,

75
00:06:50,799 --> 00:06:56,399
kako so bili navčeni, samo prva od recimo štirih, petih faz je tista,

76
00:06:56,399 --> 00:07:01,399
ki je bila posvečena temeljnemu jezikovnemu modelu, potem so bili

77
00:07:01,399 --> 00:07:06,799
pa pač prilagajani za splošno odgovarjanje. In ko jih ljudje

78
00:07:06,799 --> 00:07:11,200
na ta način dojemamo, si mislimo, da so vsi jezikovni modeli

79
00:07:11,200 --> 00:07:15,000
potem tega zmožni. Od tu potem tudi velika razočaranja,

80
00:07:15,000 --> 00:07:19,799
ko pride kakšen odprtokodni model in ne zna odgovarjati na vsa vprašanja,

81
00:07:19,799 --> 00:07:23,799
ker če čet GPT vprašate, bo karkoli zna odgovarjati, pa se zdi celosmiselno,

82
00:07:23,799 --> 00:07:29,399
kar odgovarja. Ko navčite jezikovni model na začetku, seveda tega ne zna,

83
00:07:29,399 --> 00:07:35,799
če ga ne naučite, da bo znal tudi odgovarjati na vprašanja.

84
00:07:35,799 --> 00:07:41,799
Za ta del so si konkretno pri čet GPT vzeli zelo veliko časa

85
00:07:41,799 --> 00:07:48,000
in vključili na deset tisoč inženirjev, ki so pomagali tudi pri nadzorovanem učenju

86
00:07:48,000 --> 00:07:51,799
in uporabljali še tehnike, kot so spodbojovano učenje in tako naprej,

87
00:07:51,799 --> 00:07:57,399
kar ni del učenja jezikovnega modela na začetku.

88
00:07:57,399 --> 00:08:02,600
Boš ti še dal kakšno vprašanje? Preden gremo še bistveno globlej.

89
00:08:02,600 --> 00:08:09,600
Ja. Zdaj, kot inženiri, pač doskrat smo na manj,

90
00:08:09,600 --> 00:08:15,200
uporabljamo nekaj te pač api, ki so nam dostopni, pa so nekaj mednarodnih korporacij,

91
00:08:15,200 --> 00:08:23,200
večje podjetja, pa me samo tako zanima, ne vem. Jaz pač nimam nekaj občutka,

92
00:08:23,200 --> 00:08:28,399
če obstaje nek tak model, ki je v bistvu v Slovenščini, pa ne vem,

93
00:08:28,399 --> 00:08:33,400
kako se to zdaj lahko primerja. Tako nimam nekaj občutka v bistvu,

94
00:08:33,400 --> 00:08:40,400
ja, ok, poznamo ČGPT, naredimo nek api klic, pa lahko tudi v Slovenščini,

95
00:08:40,400 --> 00:08:44,400
ampak tako, ne vem, čist, ekskluzivno v Slovenščini, ne vem,

96
00:08:44,400 --> 00:08:49,200
ne predstavljam se, kako, kje v bistvu sploh smo.

97
00:08:49,200 --> 00:08:54,400
Moja taka edina neka izkušnja je, ne vem, šel sem na nek medicinski pregled

98
00:08:54,400 --> 00:08:59,000
in potem je bil ta narekovanje in je tisto model napisal, tisto...

99
00:08:59,000 --> 00:09:02,200
Kar je slišal. Ja.

100
00:09:02,200 --> 00:09:06,200
Želja zrovnika bi bila, da bi avtomatsko napisal na mne za pomožnost

101
00:09:06,200 --> 00:09:10,200
in še diagnozo, pa to v takej strukturi, da njemu ne bi bilo treba.

102
00:09:10,200 --> 00:09:16,200
In tukaj je potem, recimo, še dodatna možnost, ki jo lahko omogoči

103
00:09:16,200 --> 00:09:20,200
jezikovni model, ampak, če se vrnem jasno na to, kar sem dojel,

104
00:09:20,200 --> 00:09:26,200
da je vaše vprašanje, sem že veliko krat slišal, da ali se nam splača

105
00:09:26,200 --> 00:09:31,200
truditi v Slovenščino, sej v nas bodo itak veliki pojedlji,

106
00:09:31,200 --> 00:09:35,200
pa tudi sej Slovenija in majh nad tržno ne zanimeva.

107
00:09:35,200 --> 00:09:39,200
Pač to so dejsta, to mi vsi vemo, ampak ne želimo zaostajati.

108
00:09:39,200 --> 00:09:44,200
In mislim, da veliki nas bojo pojedli, če bomo dali kaj za pojest.

109
00:09:44,200 --> 00:09:48,200
Sej nimajo kaj, tako da bom čisto plastičen.

110
00:09:48,200 --> 00:09:53,200
Recimo, vzemimo ČGPT, ki je bil navčen trojko,

111
00:09:53,200 --> 00:09:57,200
kot ste verjetno brali, ker je to pač javen podatek,

112
00:09:57,200 --> 00:10:01,200
je njegov model velik 175 milijard parametrov.

113
00:10:01,200 --> 00:10:06,200
In potem, če pogledamo, koliko gradiva je potrebnega za tak model.

114
00:10:06,200 --> 00:10:10,200
Veliko je bilo raziskal na to temo, koliko tolknov,

115
00:10:10,200 --> 00:10:14,200
ampak če poenostavimo, besed je potrebnih za en parametr,

116
00:10:14,200 --> 00:10:18,200
in so ta razmerja od dva, pa tudi do dvesto.

117
00:10:18,200 --> 00:10:22,200
Recimo, od dva tolkna do dvesto tolkno je potrebnih

118
00:10:22,200 --> 00:10:26,200
za en sam parametr. Pa če mi vzemimo deset, ker bo lažje računati,

119
00:10:26,200 --> 00:10:31,200
pa je to na spodnji meji, to pomeni 1750 milijard tolknov,

120
00:10:31,200 --> 00:10:36,200
ali poenostavljeno besed, rabimo za tak model.

121
00:10:36,200 --> 00:10:43,200
Zdaj, če pogledate, da je knjiga ima tipično od 50 do 100 tisoč besed.

122
00:10:43,200 --> 00:10:49,200
In če zdaj razložim še to razliko med besedami in tolkni,

123
00:10:49,200 --> 00:10:55,200
velike jezikovni modeli se ne učijo, njihov slovar niso samo besede,

124
00:10:55,200 --> 00:10:59,200
ampak so tudi delčki besed. Na ta način lahko pokrijo potem tudi besedišče,

125
00:10:59,200 --> 00:11:03,200
ki ga pač trenutno še nimajo vokebolarja, torej nova imena in tako naprej,

126
00:11:03,200 --> 00:11:07,200
lahko se stavijo vseh delčkov. In običajni velike jezikovni modeli

127
00:11:07,200 --> 00:11:11,200
imajo tam nekaj od 50 do 100 tisoč tolkno.

128
00:11:11,200 --> 00:11:14,200
In od tega je 20 do 30 procentov kar celih deset,

129
00:11:14,200 --> 00:11:18,200
ampak so to najpogostejše besede. Tako da, če bi zdaj eno knjigo vzeli

130
00:11:18,200 --> 00:11:23,200
in jo tokenizirali, bi se lahko pokazali, da je tam od 50 do 70 procentov

131
00:11:23,200 --> 00:11:27,200
tolkno. To je kar z besedami tokenizirano, ostalo pa z delčke.

132
00:11:27,200 --> 00:11:31,200
Če to upoštevamo, pridemo do nekega razmira okrog ena in pol,

133
00:11:31,200 --> 00:11:37,200
ena šest tolkna na besedo. Če to upoštevamo pri pokrečni knjigi,

134
00:11:37,200 --> 00:11:42,200
ki je tam od 50 do 100 tisoč besed, vzajemimo 80 tisoč besed,

135
00:11:42,200 --> 00:11:46,200
krta 1,6 ali 1,5, pridemo na cirka 130 tisoč.

136
00:11:47,200 --> 00:11:52,200
Zdaj, poglejmo tiste parametri odprej, milijardo 370 tisoč,

137
00:11:52,200 --> 00:11:56,200
se mi zdaj se nekaj. Če to zdelimo, pridemo na neke dobrih

138
00:11:56,200 --> 00:12:02,200
10 milijonov knjig. Slovenija vsako leto sproducira 5 tisoč.

139
00:12:02,200 --> 00:12:05,200
Torej, 3 tisoč let idemo producirati in bomo imeli tolk knjig.

140
00:12:05,200 --> 00:12:10,200
To je samo za občutek, kaj pomenijo velike količine.

141
00:12:10,200 --> 00:12:18,200
V primjeru LMA, in knjige so bile pri ČGPT-u 20% vsebine,

142
00:12:18,200 --> 00:12:25,200
menj da, sej tega noben prozarez točno ne vejo, ampak če želimo raznovrstnost,

143
00:12:25,200 --> 00:12:31,200
potem moramo vključiti še veliko drugega gradiva in kje ga v Sloveniji

144
00:12:31,200 --> 00:12:38,200
sploh dobiti. Je pa dejsto, da to, kar nam zdaj ponujajo večjezikovni

145
00:12:38,200 --> 00:12:44,200
modeli, ker znajo tudi Slovenščino, pa vzamejo to, kar je možno

146
00:12:44,200 --> 00:12:49,200
z interneta vzeti. Zato, ker so projekti, ki krolejo z interneta

147
00:12:49,200 --> 00:12:53,200
masovno vse vsebine in koliko se Slovenščine vjame, se jo vjame.

148
00:12:53,200 --> 00:12:57,200
Ampak to je Slovenščina kakršna je, kar je pač na spletu,

149
00:12:57,200 --> 00:13:03,200
ni nič kontrolirano. Na koncu, prvi modeli so res bili navčeni

150
00:13:03,200 --> 00:13:07,200
z enimi gromozanskimi masami. Zdaj je pa jasno, da poleg mas

151
00:13:07,200 --> 00:13:13,200
pomembna kvaliteta. Ne smem reči, da je najboljši, ampak zelo dober

152
00:13:13,200 --> 00:13:20,200
jezikovni model za področje medicine je MedPalm 2 od Googla, ki je,

153
00:13:20,200 --> 00:13:26,200
mislim, da dosegu na testih, ki jih polage v Ameriki zdravniki,

154
00:13:26,200 --> 00:13:31,200
da dobijo licenco, imajo imel 60%, s tem modelom so dobili, mislim,

155
00:13:31,200 --> 00:13:40,200
87% pravilne odgovore. In tam je zelo pomembno, kaj so viri.

156
00:13:40,200 --> 00:13:45,200
Viri so celo previrjeni. Mi pa govorimo o več jezikovnih modeli,

157
00:13:45,200 --> 00:13:50,200
kjer se je slučajno vjela neka Slovenščina. In vjelo se je zelo malo.

158
00:13:50,200 --> 00:13:56,200
Potem je vprašanje, saj so prevajalniki strojni, zakaj se itak,

159
00:13:57,200 --> 00:14:02,200
brezveza, da mi nekaj delamo o Slovenščino. Mislim, če se poglobite v to,

160
00:14:02,200 --> 00:14:08,200
kako delujo jezikovni modeli, potem boste ugotovili, da je zelo pomembno,

161
00:14:08,200 --> 00:14:14,200
kaj mi damo na izvoru. Velike jezikovni modeli se na masah naučijo

162
00:14:14,200 --> 00:14:22,200
gramatike, sintakse, pragmatike, semantike, izjemno veliko jezikovnih

163
00:14:22,200 --> 00:14:26,200
značilnosti, ki jih mi niti nekatere pojmenovati ne znamo, se vjamajo

164
00:14:26,200 --> 00:14:32,200
v neuronski mreži. Ampak to se vjamajo iz velike, velike mase in raznovrstnosti

165
00:14:32,200 --> 00:14:37,200
gradiva. Če bomo mi strojno prevedli, bomo dobili izjemno osiromašeno,

166
00:14:37,200 --> 00:14:42,200
gledano iz stališča jezikovnih značilnosti, izjemno osiromašeno besedilo.

167
00:14:42,200 --> 00:14:48,200
In posledično se model tega ne bo navadil. Tako da mislim, da je edina pot,

168
00:14:48,200 --> 00:14:52,200
če želimo za Slovenščino poskrbeti, je, da poskrbimo, da bo čim več viro

169
00:14:52,200 --> 00:14:59,200
nam voljo in ne samo za Slovenščino, ampak kar za celo družino jezikov,

170
00:14:59,200 --> 00:15:06,200
slovanskih recimo, ker so si vsaj do neke mire podobni in se bo model lahko učil

171
00:15:06,200 --> 00:15:11,200
iz skupnih glasnosti. In pa, da so ti viri kolikor je le možno nam voljo.

172
00:15:13,200 --> 00:15:16,200
Mi celo izvajamo en tak projekt na fakulteti, se je vodi ga Kriminaloški

173
00:15:16,200 --> 00:15:24,200
inštitut in pač pravna stroka, ki je namenjen temu, da trasiramo pot,

174
00:15:24,200 --> 00:15:29,200
kako nej raziskovalec pride do podatkov, če so ti posebnih kategorij,

175
00:15:29,200 --> 00:15:35,200
z namenom, da bo iz teh podatkov naredil model, ki je lahko v javno dobro

176
00:15:35,200 --> 00:15:41,200
in ne razkriva več teh podatkov, na katerih se učil. Ker mi imamo tukaj

177
00:15:41,200 --> 00:15:47,200
zelo zvezane roke. Nedavno nazaj, dve leti nazaj, mislim, da je AMZS

178
00:15:47,200 --> 00:15:57,200
pa Zveza potrošnikov so dali pobudo v državni zbor, da nekaj ukrenemo,

179
00:15:57,200 --> 00:16:01,200
ker vozila, ki jih kupujemo v Sloveniji, ne razumejo slovensko,

180
00:16:01,200 --> 00:16:04,200
ne govorijo slovensko, ne moremo se z njimi pogovarjati v slovenščini.

181
00:16:04,200 --> 00:16:10,200
Zakaj? Ne, je tako. In ko smo se obrnili potem na Volkswagen

182
00:16:10,200 --> 00:16:15,200
in tako naprej, smo na koncu prišli do Nemče in se je počas poteka,

183
00:16:15,200 --> 00:16:20,200
ampak na koncu so rekli, dajte nam podatke. Katere podatke z njih lahko damo?

184
00:16:20,200 --> 00:16:26,200
Eno vprašanje tudi med pripravo epizode, smo se pogovarjali,

185
00:16:26,200 --> 00:16:32,200
pa ste omenili, da bomo spremenili zakonodaje vse spremeninja,

186
00:16:32,200 --> 00:16:37,200
zakonodaje za to, da bodo na voljo več tih verov. A to poteka neka inicitiva

187
00:16:37,200 --> 00:16:42,200
na evropski ravni ali slovenske? Kaj je s tem? Bo treba tudi zakonodaje

188
00:16:42,200 --> 00:16:45,200
na nek način pripraviti, da boste dobili tudi dodatne vire?

189
00:16:45,200 --> 00:16:49,200
Zakon o rizikovalni dejavnosti se je že spremenil, ampak dopušča različna

190
00:16:49,200 --> 00:16:55,200
interpretacija. Lahko vam povem primjer iz tega našega konkretnega projekta.

191
00:16:55,200 --> 00:17:00,200
Mi smo dali zaprosilo na sodišča, da nam dajo podatke, ker tam se zelo

192
00:17:00,200 --> 00:17:07,199
veliko obravnav snema in potem jih zapisnikarke sada transkribirajo.

193
00:17:07,199 --> 00:17:13,199
In to je odlično učno gradivo lahko. In tega se nabere ogromno in v vseh,

194
00:17:13,199 --> 00:17:20,199
recimo, letih do zdaj se je tudi nabralo. Ampak nismo dobili teh podatkov,

195
00:17:20,199 --> 00:17:29,199
ker po tem zakonu imamo prvico do njih, ampak na drugi strani pa to,

196
00:17:29,199 --> 00:17:36,199
ne sme lastniku ali pa upravljalcu podatkov naprtiti tako veliko dela,

197
00:17:36,199 --> 00:17:43,199
da to ne odtehta koristnosti tega, kar bomo naredili. In jaz tudi razumem

198
00:17:43,199 --> 00:17:49,199
zdaj pač, da odgovor niko, ker so nekaj teh podatkov arhivirali na zelo

199
00:17:49,199 --> 00:17:53,199
različne načine in ni preprosto niti uparit več zvočnega posnetka,

200
00:17:53,199 --> 00:17:56,199
stranskribirati in tako naprej. Razumem, ampak hočem povejati,

201
00:17:56,199 --> 00:18:03,199
zakonodaja gre nekoliko v to smir in nam daja več možnosti, ampak do podatkov

202
00:18:03,199 --> 00:18:07,199
še vedno zelo težko pridemo. Lahko vprašamo na RTV za podatke,

203
00:18:07,199 --> 00:18:12,199
pa jih zopet ne bomo dobili, ker so avtorske prvice. In to gre zelo,

204
00:18:12,199 --> 00:18:19,199
zelo počasi naprej. To, kar bi jaz želel povdariti pa je, da majhno Slovenije

205
00:18:19,199 --> 00:18:24,199
narekuje, da smo tukaj mogoče malo bolj inovativni in pikso bolj odprti.

206
00:18:24,199 --> 00:18:28,199
Z vsemi seveda varovali, kot mi, ki so potrebne.

207
00:18:30,199 --> 00:18:34,199
En zelo velik del jezikovnih tehnologij, ne hočem reči starih,

208
00:18:34,199 --> 00:18:40,199
ampak tradicionalnih, so korpusi. Se pravi, a lahko razložiš,

209
00:18:40,199 --> 00:18:46,199
kaj so korpusi, kako se pripravljajo recimo, pa če so še uporabni

210
00:18:46,199 --> 00:18:49,199
pa uporabljeni tudi za izdelavo teh modelov?

211
00:18:50,199 --> 00:18:54,199
Mislim, ja, korpusi so zelo različne stvari in to je mogoče bolj vprašanje

212
00:18:54,199 --> 00:18:58,199
za jezikoslovce. Ampak jaz lahko povem, kaj so za nas tehnike,

213
00:18:58,199 --> 00:19:03,199
korpusi in kje jih uporabljamo. Pri obdelavi naravnega jezika je seveda

214
00:19:03,199 --> 00:19:07,199
zelo pomembno, da mi poznamo celotno besedišče in da tudi za vsako

215
00:19:07,199 --> 00:19:13,199
besedo vemo, kaj je njena lema, kakšne oblike ima in tako naprej.

216
00:19:13,199 --> 00:19:18,199
In zakaj? Zato, ker potem lahko sisteme naučimo, da ko obdelujejo

217
00:19:18,199 --> 00:19:24,199
naravno besedilo, tudi iz podatka o tem, kaj je, kakšna je, ne vem,

218
00:19:24,199 --> 00:19:29,199
oblikoslovna oznaka neke besede v besedilu, znajo iz tega potem tudi

219
00:19:29,199 --> 00:19:34,199
prideti do recimo ustreznih sklepov in podobno ali pa reševati naloge,

220
00:19:34,199 --> 00:19:39,199
ki jih pa zadamo. Zato potrebujemo razno, raznog korpuse.

221
00:19:39,199 --> 00:19:43,199
Ampak so uporabljeni tudi pri gradnji LLM-ov ali ne?

222
00:19:44,199 --> 00:19:48,199
To so pa dodatna znanja, ki jih lahko dodamo pri učenju LLM-ja.

223
00:19:48,199 --> 00:19:54,199
Drugače, pri LLM-jih, tako kot so bili že v začetku, začeti njihov učenje,

224
00:19:54,199 --> 00:19:59,199
kako se je izdelovalo, je preprosto na ogromnih masah podatkov,

225
00:19:59,199 --> 00:20:04,199
ker se LLM-ji, ki temelijo na generativni umetni inteligenci,

226
00:20:04,199 --> 00:20:14,199
da poskušajo razumeti vsa jezikovne značilnosti v masah besedila,

227
00:20:14,199 --> 00:20:20,199
da potem izdelajo kar najboljšo predikcijo nasledne besede iz konteksta,

228
00:20:20,199 --> 00:20:26,199
ki ga imajo. Ker jezikovni modeli, generativni, generirajo nasledno besedo

229
00:20:26,199 --> 00:20:30,199
na osnovi promta, ki ste jim ga dali, ampak ne sveda samo ene besede,

230
00:20:30,199 --> 00:20:37,199
temveč je tukaj zelo velik tehnik, kako se potem formira odgovor.

231
00:20:38,199 --> 00:20:43,199
Ko smo se pripravljali na to epizodo, smo v bistvu, no, vsej jaz,

232
00:20:43,199 --> 00:20:52,199
ker nisem poznal, sem bil presenečen, koliko dobrih teh osnovnih podatkov je,

233
00:20:52,199 --> 00:20:58,199
to so prav neki portalev je, ki so fokusirani na Slovenščini,

234
00:20:58,199 --> 00:21:02,199
tam se najde korpusa. Če to se pravi nekdo, ki se hoče mičkem poigrati,

235
00:21:02,199 --> 00:21:10,199
ni za nas tako, da se malo poigraš. So te podatke na voljo,

236
00:21:10,199 --> 00:21:17,199
pač te portali so precej urejeni. Jaz sem bil navdušen na nek način,

237
00:21:17,199 --> 00:21:21,199
da pač te stvari so. Ker je mogoče kažen komentar glede tega,

238
00:21:21,199 --> 00:21:25,199
pač ogromno enega dela je že dejansko bilo narejeno, pa je zelo lično

239
00:21:26,199 --> 00:21:30,199
tudi predstavljeno. Drži, zelo veliko dela na to temo je bilo narejenega,

240
00:21:30,199 --> 00:21:39,199
ampak je treba vedjeti, da veliko dela je bilo narejenega že preden so se pojavili

241
00:21:39,199 --> 00:21:44,199
velike jezikovni modeli in je bilo to delo opravljeno z res željo

242
00:21:44,199 --> 00:21:51,199
digitalizacije in prezervacije tudi jezika, ker seda ni edini cilj,

243
00:21:52,199 --> 00:21:57,199
da mi digitaliziramo jezik ta, da lahko potem gradimo tehnične rešitve,

244
00:21:57,199 --> 00:22:01,199
ampak je tudi zato, da pravučujemo jezik kot jezik in to je jezik v Slovci

245
00:22:01,199 --> 00:22:06,199
in še mnogi drugi počnejo in je mislim, da desetletje če ne več raziskovalnega

246
00:22:06,199 --> 00:22:11,199
truda iz različnih oddelkov, različnih fakultet in univerz v Sloveniji

247
00:22:11,199 --> 00:22:18,199
bilo narejenega v mogoče dvajsetih letih in od tem potem tudi dostopnost tega.

248
00:22:19,199 --> 00:22:25,199
Nažalost pa, ko govorimo o velikih jezikovnih modelih, je pa to pač osnova,

249
00:22:25,199 --> 00:22:30,199
ki jo imamo, ampak je preprosto premajkana, pač nam ne pomaga.

250
00:22:30,199 --> 00:22:36,199
Moramo pa sedaj ločiti gradnja jezikovnega modela ali pa specializacija

251
00:22:36,199 --> 00:22:41,199
jezikovnega modela. Mi lahko danes že kakšen večjezični jezikovni model

252
00:22:41,199 --> 00:22:45,199
specializiramo za točno konkretno nalogo in jo bo lahko tudi za slovenščino

253
00:22:45,199 --> 00:22:50,199
dobro izvajalo. Ampak ne moramo pa narediti ravno, kar se izmislimo,

254
00:22:50,199 --> 00:22:55,199
če želimo delati nekaj na področju medicine. Dokler ni slovenska medicina

255
00:22:55,199 --> 00:22:59,199
vključana v velikih jezikovnih modelih, bo to predvsej težje, ker niti

256
00:22:59,199 --> 00:23:03,199
terminologije ne bo razumel. Nič od tega se ni naučil v postopku,

257
00:23:03,199 --> 00:23:06,199
če je nekaj tega nimelo.

258
00:23:06,199 --> 00:23:11,199
Za predah predam, vprašam še malo več detajlov o large modelih.

259
00:23:12,199 --> 00:23:18,199
A me lahko predstaviš, tudi našem odencu, projekt Slovensčina PKEU?

260
00:23:19,199 --> 00:23:24,199
To je del RSD, če sem prav. Mislim, da je Andraž predvsem na tolj

261
00:23:24,199 --> 00:23:31,199
na taj tule cilo. A lahko malo to razložiš, ker je en kup zelo zanimivih

262
00:23:31,199 --> 00:23:36,199
in uporabnih vrodi, ki je razvitih v tem segmentu razvijalih.

263
00:23:37,199 --> 00:23:41,199
Lahko seveda. Razvoj slovenščine v digitalnem okolju je bil, mislim,

264
00:23:41,199 --> 00:23:47,199
da prvi tak velik projekt, kjer smo se združili vsi, ki se s tem ukvarjamo,

265
00:23:47,199 --> 00:23:51,199
v Sloveniji. Ministrstvo za kulturo je bil sofinanser, pa tudi kar veliko

266
00:23:51,199 --> 00:23:55,199
denarja so zbrali, mislim, da je bil štirimiljonski projekt.

267
00:23:55,199 --> 00:24:00,199
Cilj je pa bil, da pripravimo tako vire, torej tam se je tudi zbralo

268
00:24:00,199 --> 00:24:04,199
nekaj korpusov in tako naprej ali pa odkupilo celo. Denar smo imeli

269
00:24:04,199 --> 00:24:09,199
povanje, da smo zdaj javno na voljo. Plus, da so se gradile rešitve

270
00:24:09,199 --> 00:24:14,199
s področja obdelave naravnega jezika in pa gradile so se rešitve

271
00:24:14,199 --> 00:24:19,199
s področja govornih tehnologij. To pomeni prepoznava slovenskega govora,

272
00:24:19,199 --> 00:24:24,199
prevajenje slovenščina, angliščina, angliščina, slovenščina in pa,

273
00:24:24,199 --> 00:24:29,199
kar je verjetno tudi zelo pomembno, pripraviti smo morali tisočurno

274
00:24:30,199 --> 00:24:35,199
podatkovno bazo posnetkov javnega govora, privatnega govora,

275
00:24:35,199 --> 00:24:41,199
branega govora in tako naprej, kar je lahko osnova potem za razpoznavalnike

276
00:24:41,199 --> 00:24:48,199
in to tako nabrati, da je ta zdaj množica na voljo tudi za komercijalno

277
00:24:48,199 --> 00:24:54,199
rabo, brez omejitev. Potem smo pa na osnovi te množice tudi naredili

278
00:24:54,199 --> 00:24:59,199
javno dostopen razpoznavalnik in privajalnik. Razpoznavalnik je prejši

279
00:25:00,000 --> 00:25:02,840
in za Slovenščino je, mislim, da imel 30-procentno napako,

280
00:25:03,080 --> 00:25:06,160
tega, kar smo ga potem naredili, je padel pod deset, mislim,

281
00:25:06,400 --> 00:25:10,400
da je za neke množice bil na šest procentov, kar je veliko boljši.

282
00:25:10,640 --> 00:25:15,000
In pa prevajalnik se je pa tudi za določena področja obnesel

283
00:25:15,240 --> 00:25:20,200
celo boljši kot Google-ov, za določena področja pa ne.

284
00:25:20,440 --> 00:25:25,879
In to je tudi javno na voljo in podjetja že kar to uporabljajo.

285
00:25:26,040 --> 00:25:30,840
Tako da, jaz mislim, da je ta projekt bil zelo koristen,

286
00:25:31,080 --> 00:25:35,840
kar smo mogoče malo pogrešali, je dejansko razumevanje

287
00:25:36,080 --> 00:25:39,400
na strani naročnika, kaj je naročeno, ker to spada pri nas

288
00:25:39,639 --> 00:25:43,200
v resor ministerstva za kulturo, zelo pohvalno je, da so to

289
00:25:43,439 --> 00:25:47,639
financirali, ampak mislim, da je na njihovi strani tudi verjetno

290
00:25:47,880 --> 00:25:51,799
sami priznajo mogoče malo manjko tehničnega razumevenja,

291
00:25:51,959 --> 00:25:57,959
kaj pa še manjka, pa po kateri poti naprej in ta del recimo

292
00:25:58,200 --> 00:26:03,200
je za nas mogoče malo neugoden, ker moramo potem na različnih

293
00:26:03,439 --> 00:26:06,440
resorih, zdaj kot veste z novo vlado smo dobili še ministerstvo

294
00:26:06,680 --> 00:26:09,959
za digitalno obrazbo, pa potem ne vemo več, koga je treba

295
00:26:10,199 --> 00:26:12,919
pripričavati, da se taki projekti ne smejo staviti, ker če

296
00:26:13,160 --> 00:26:16,400
se bojo, bomo stali na neki točki in tista točka bo k malu

297
00:26:16,800 --> 00:26:19,199
ne spet ne bo dovolj dobra.

298
00:26:19,440 --> 00:26:25,800
En izjemno dober, izjemno dobra stvar, ki ste naredili pred

299
00:26:26,040 --> 00:26:31,400
tem projektu Slovenščina EU je, da vsi ti tuli imajo pač web

300
00:26:31,639 --> 00:26:35,000
interfejs in jih lahko danes uporabiš, preveriš in se jih

301
00:26:35,239 --> 00:26:39,320
preizkusiš in jih danes tudi uporabljaš, to je izjemno, zelo

302
00:26:39,559 --> 00:26:43,919
dobro je pa tudi, da je vsa koda tudi na GitHubu in jo lahko dol

303
00:26:43,919 --> 00:26:49,000
potegneš, pregledaš. Tudi videl sem, da ljudje danes tudi pol

304
00:26:49,239 --> 00:26:54,279
rekveste odpirajo in danes ni samo nek raziskovalni projekt,

305
00:26:54,519 --> 00:26:57,400
ki bi bil nared zaradi raziskovalnega projekta, pa potem

306
00:26:57,639 --> 00:27:01,440
obtičal v nekih akademskih arhivih, ampak deluje kot, da je

307
00:27:01,680 --> 00:27:05,239
interes tudi širše publike, da vam pomaga pred tem, tako občutek

308
00:27:05,480 --> 00:27:10,360
imam. Drži, moram pa vse note malo popraviti. Vse je res

309
00:27:10,520 --> 00:27:15,759
na voljo, ampak to, kar pogosto naletimo na nerazumevanje,

310
00:27:16,000 --> 00:27:24,800
je, model je model, samo sebe to ni rešitev. Če nekdo, mi naredimo

311
00:27:25,039 --> 00:27:28,639
model za prepoznavo Slovenščine, nekdo že pričakuje, da bo zaimel

312
00:27:28,880 --> 00:27:32,000
podnapise na televiziji, ki se generira avtomatsko v realnem

313
00:27:32,240 --> 00:27:38,759
času. To pomeni še dost zapletena uporaba takega modela ali pa

314
00:27:38,839 --> 00:27:45,320
celo nekega modela, ki je iz tega navčen. Ta problem je kar bil velik,

315
00:27:45,559 --> 00:27:49,360
smo upazni, pa tudi, ne vem, mi smo naredili demonstracijsko

316
00:27:49,600 --> 00:27:53,000
na slovenščina.eu portal, kjer lahko, ne vem, odložite nekaj

317
00:27:53,240 --> 00:27:56,360
besedila in dobite transkript, ampak je bilo omejeno na pet minut,

318
00:27:56,600 --> 00:27:59,479
zakaj jaz, zato ker nimamo takega hardlera, da bi celi Sloveni

319
00:27:59,720 --> 00:28:03,199
to ponujali. Imate za to model, si ga morate vzeti, pa mogoče

320
00:28:03,440 --> 00:28:06,600
naredite eno lupino okrog njega. Ta del tudi ni bil nekak, ga je

321
00:28:06,679 --> 00:28:12,000
težko razumeti ljudem, ki pač celo namenijo so za kulturo,

322
00:28:12,240 --> 00:28:15,839
so rekli, a pa se jaz, mi smo dal toliko velik delarja.

323
00:28:16,080 --> 00:28:21,000
Moramo potem razložiti, da aplikacija ni isto kot model.

324
00:28:21,240 --> 00:28:24,559
Model vam omogoča, da razvijate zelo različne rešitve,

325
00:28:24,800 --> 00:28:28,919
ni pa to končna rešitev in v končni fazi mislim, da je to tudi

326
00:28:29,160 --> 00:28:34,600
smiselna meja. Dobro, da sem pred držnik dal v avto.

327
00:28:34,759 --> 00:28:38,759
Da je to smiselna meja med tem, kaj ne je dela raziskovalna skupnost,

328
00:28:39,000 --> 00:28:43,199
ki je financirana mogoče javno in kaj ne je dela privat sektor.

329
00:28:43,440 --> 00:28:48,080
Privat sektor v Sloveniji ne bo vlagal v pripravo stvari,

330
00:28:48,320 --> 00:28:53,080
ki so potrebne za Slovenščino v tem smislu, kot sem zdaj govoril,

331
00:28:53,320 --> 00:28:56,199
ker je to predrago, vam povem čisto plastično. Če želite

332
00:28:56,440 --> 00:29:00,320
narediti sintetizator za Slovenščino, potrebujete profesionalnega

333
00:29:00,440 --> 00:29:06,000
govorca, ki bo šel snemati v profesionalni studio, 25 do 50 ur bo posnel,

334
00:29:06,240 --> 00:29:10,039
to mu boste plačali, potem morate pa še odkupi prvice, ki so dost zapretene,

335
00:29:10,279 --> 00:29:14,160
ker bom dal svoj glas, na njegov glas se bo posod pojavljal.

336
00:29:14,399 --> 00:29:19,920
In to nekaj stane. Pri velikih, ki jih ne bom imenoval,

337
00:29:20,160 --> 00:29:24,720
lahko sintezo kupite en milijon znakov za dvojst dolarjev.

338
00:29:24,959 --> 00:29:30,160
Kdo bo to delal potem v Sloveniji? Nobeden. Zato je do neke točke

339
00:29:30,399 --> 00:29:36,600
mora prpeljati država, če želi, da se bodo razvijale rešitve,

340
00:29:36,839 --> 00:29:41,440
ki pa imajo lahko viseno više dodano vrednost kot ta osnova.

341
00:29:43,320 --> 00:29:45,320
Boš še ti?

342
00:29:45,559 --> 00:29:49,760
Naj, meni se zdi fascinantno. Zdaj, sem sam fascineran.

343
00:29:50,000 --> 00:29:53,920
Za poslušalce, ja, v zvoni je začelo močno padeti dež.

344
00:29:54,160 --> 00:29:58,320
Bo o to kaj povedal o naših podpornikih.

345
00:29:59,119 --> 00:30:03,119
A smo že na tistem trenutku? Tako, da malo zaprsekat.

346
00:30:03,359 --> 00:30:08,559
Ogrodje je možno zaradi izjemnih podpornikov via Patreon,

347
00:30:08,799 --> 00:30:13,920
ki nas podpirajo z mesečnimi donacijami in zato tudi dobijo

348
00:30:14,160 --> 00:30:18,880
ekskluzivno dostop do sebine pred in gre tudi javno na volje vsem.

349
00:30:19,119 --> 00:30:25,040
Ogrodje ima tudi podpornike, ki jo umogočajo, in to so tri podjetja,

350
00:30:25,200 --> 00:30:29,679
Human for Rock, TriFace in Kaldi, ki smo zelo hvaležni, da nas podpirajo,

351
00:30:29,920 --> 00:30:34,239
da lahko delamo to na tem nivoju. A boš še ti rekel like in subscribe?

352
00:30:34,480 --> 00:30:37,600
Ja, like and subscribe, pa povedajte svojim kolegom,

353
00:30:37,839 --> 00:30:42,720
če ne poznajo, da naj poslušaj eno epizodo in potem,

354
00:30:42,959 --> 00:30:45,119
če je v redu, naj poslušaj eno.

355
00:30:45,359 --> 00:30:50,000
Ok, to je pp. Hvala sem. Jaz bi šel zdaj mogoče malo nazaj

356
00:30:50,160 --> 00:30:56,559
na te language modele. Ogotovili smo, da rabiš veliko volumna,

357
00:30:56,799 --> 00:31:00,320
ogotovili smo, da je zakonodaja zanimiva, ogotovili smo, da je treba

358
00:31:00,559 --> 00:31:05,440
nek filtering, nek treba je paziti, kaj gre noter. Ogotovili smo,

359
00:31:05,679 --> 00:31:08,959
kje je približno pridajo podatki. Zdaj nam je pa malo bolj zanima

360
00:31:09,200 --> 00:31:14,399
ta tehnološki aspekt, kako seletevate teh ETL pipeline-ov

361
00:31:14,559 --> 00:31:20,959
za ta volumen podatkov, gledamo tudi, da je to neka Java data konferenca.

362
00:31:21,200 --> 00:31:26,320
A lahko malo več od teh področjih, koliko energije, resursov

363
00:31:26,559 --> 00:31:30,160
potrebujete investirati v pripravo tehnologije, da lahko sploh

364
00:31:30,399 --> 00:31:32,320
treniramo te modele. Lahko je več o tem?

365
00:31:32,559 --> 00:31:36,640
Ja, lahko poskusim. Zdaj, zadnji projekt, ki ga zvajamo,

366
00:31:36,880 --> 00:31:41,839
je ta projekt Povejmo, v okviru tega projekta moramo izdelati

367
00:31:42,799 --> 00:31:47,600
najprej en manjši slovenski model, ki bo imel eno milijardo parametrov,

368
00:31:47,839 --> 00:31:51,839
potem pa desetmilijardnega. Tega manjšega delamo zato, da bo delal

369
00:31:52,079 --> 00:31:57,440
tudi na napravah, kot so telefone in podobno. Ne izhajamo iz nič,

370
00:31:57,679 --> 00:32:03,600
temveč smo vzeli podobno velike druge modele, tuje, ki jih potem

371
00:32:03,839 --> 00:32:09,200
učimo naprej. Poziroma so tehnike zelo različne. Prej sem že malo

372
00:32:09,279 --> 00:32:14,480
omenjal tokenizacijo, to verjetno mnogi, ki ste tehniki v tem razumete.

373
00:32:15,600 --> 00:32:21,519
Mi, če izhajamo iz nekega drugega modela, lahko seveda ohranimo

374
00:32:21,760 --> 00:32:27,440
njihov vokebularij. Ampak to seveda ne bo idealno, ker je slovenščina

375
00:32:27,679 --> 00:32:32,000
drugačen jezik, ima drugo besedišče. Verjetno so pa kažni koščkine,

376
00:32:32,239 --> 00:32:35,440
ki so podobni, pa mogoče celo pomensko podobne kakšne besede,

377
00:32:35,440 --> 00:32:40,399
ampak tega je zelo malo. Tako da se vedno splača odnorditi potem nov slovar.

378
00:32:41,839 --> 00:32:44,399
In mi smo ga tudi naredili, ampak ne želiš pa zgubiti vsega tega,

379
00:32:44,640 --> 00:32:47,359
kar se je naučil v osnovni model. Tako da potem so neke tehnike,

380
00:32:47,600 --> 00:32:53,279
kako prenašamo tisto znanje iz prvega modela na naš začetnik,

381
00:32:53,519 --> 00:32:58,000
ki ga potem učimo z našimi besedili. Kar se tiče nabiranja glediva

382
00:32:58,239 --> 00:33:03,440
je nažalost tako zelo kaubojsko, ker eni nam bi dal na disko,

383
00:33:04,160 --> 00:33:08,320
eni bi, ne vem, pošiljali, eni bi, ne vem, to pritestovrnjakom.

384
00:33:08,559 --> 00:33:13,040
Je zelo različno. To, kar poskušamo mi profesionalizirati,

385
00:33:13,279 --> 00:33:16,480
je zgolj od te točke naprej, ko pride na fakulteto.

386
00:33:16,720 --> 00:33:20,399
To pa pomeni ustrezne schrambe, ki so ustrezno varovane.

387
00:33:21,839 --> 00:33:25,440
Jasno, po dostopu kot tudi sicer, da se podatke ne zgubijo.

388
00:33:25,679 --> 00:33:29,279
In ampak na konc koncu tukaj ne gre za tako,

389
00:33:29,440 --> 00:33:33,039
da je volumen je velik, ampak količina v terabajtih pa vseeno

390
00:33:33,280 --> 00:33:36,960
ni tako grozna, da bi v nezavest padel. To brez težav.

391
00:33:37,200 --> 00:33:42,080
Nekako pohendljamo. Potem pridajo pa resursije,

392
00:33:42,320 --> 00:33:46,799
se pravi računski viri, ki jih moramo uporabiti za obdelavo.

393
00:33:47,679 --> 00:33:53,440
Tukaj posegamo po VEGI. VEGA je znan HPC, ki je postavljen

394
00:33:53,679 --> 00:33:57,760
v Mariboru, ma za tiste, ki razumete GPU tehnologijo,

395
00:33:57,919 --> 00:34:02,960
ves se, da ima, ali pa povem, ima 64 vzgljišč po 4 A100 kartic.

396
00:34:03,200 --> 00:34:07,200
To je sicer že malo zastavljena tehnologija, ampak vseeno je to,

397
00:34:07,440 --> 00:34:11,760
kar je za naše razmire in za našo količino podatkov to zadošča.

398
00:34:12,000 --> 00:34:17,679
Imamo pa na fakulteti naši tudi zdaj že, mislim, da 12 H100 kartic,

399
00:34:17,919 --> 00:34:22,799
ki so boljše že. In v postopku smo postavili tvoje novega podatka

400
00:34:22,880 --> 00:34:27,039
nega centra, ki bo imel pa, mislim, GB200, če nam ga bo en video

401
00:34:27,280 --> 00:34:32,880
res dala. Ta pa ne bi bil po petah flopsih tam, tam z VEGO.

402
00:34:34,000 --> 00:34:38,400
Ampak v eni omari vodno hlajenje. In to bo v kontenerju na strehi

403
00:34:38,640 --> 00:34:42,479
na fakulteti. In to bo pločeval za elektriko, saj še nismo zmenjni.

404
00:34:44,000 --> 00:34:49,039
Ampak, ja, bo pa, mislim, da imamo še leto pa polčasa, da zaključimo

405
00:34:49,200 --> 00:34:51,200
to postavitev.

406
00:34:52,080 --> 00:34:54,080
Ne, sem odgovoril.

407
00:34:54,080 --> 00:34:56,880
Ne, jaz sem rekel, Andražo, da Hardware-ske vprašanja bom njemu dal.

408
00:34:56,880 --> 00:34:57,520
Meni?

409
00:34:57,520 --> 00:34:58,239
Ja, dej še eno.

410
00:34:58,239 --> 00:35:01,440
Ne, ne, sej. Meni je samo veseli,

411
00:35:03,919 --> 00:35:07,520
ljudje so dostkrat kritični, se mi zdi, tako lajki, ali pa pač ljudje se radi

412
00:35:07,520 --> 00:35:10,719
pretožujem, in pa smo tako, ok, zakaj ravno zdaj ta, ne vem,

413
00:35:11,840 --> 00:35:17,520
HPC, a ne. A se vam zdi, da zdaj v bistvu, ko so te LLM-i mičkom bolj

414
00:35:17,520 --> 00:35:21,919
popularni, da bom mogoče malo več, ne bom nekoglih usmiljen, ampak malo več

415
00:35:21,919 --> 00:35:26,799
sprejemanja, ja, pač, seveda zdaj rabeš pa GPU-je, a ne, oziroma pač nekaj,

416
00:35:26,799 --> 00:35:28,799
nekaj, nekaj takaj jadra.

417
00:35:30,000 --> 00:35:33,119
Mislim, zdaj sem v dilemiji, kaj ne odgovorim, ne, ker jaz

418
00:35:33,119 --> 00:35:36,559
posebno kot jaz si mislim, da imamo več, kot rabimo, a ne.

419
00:35:37,440 --> 00:35:41,039
V svoji vlogi profesorja na fakulteti pa mislim, da še premal.

420
00:35:41,599 --> 00:35:47,599
Ne moramo dohajati drugih potem, je, mislim, nesmiselno, mi vse čas

421
00:35:47,599 --> 00:35:51,280
se želimo premirjati z najboljšimi in tako naprej, pri jeziku imamo

422
00:35:51,280 --> 00:35:55,679
še druge umetnice, jasno, in potem ne moramo, mislim, potem moramo

423
00:35:55,679 --> 00:35:58,000
iti po isti pot, in ni druga izbira, a ne.

424
00:35:59,280 --> 00:36:04,000
Stališča, a ne, kaj nam pa to prinaša, je pa pač seda drugo vprašanje

425
00:36:04,000 --> 00:36:07,520
in ima tudi svojo filozofsko dimenzijo, tega se pa ne bom spuščal.

426
00:36:08,479 --> 00:36:11,280
Prav, to so tisto vprašanje, ki jih ne smemo postaviti.

427
00:36:13,840 --> 00:36:17,840
Pa on pa še tako, ne vem, čist tako, ok, smo na Java konferenci,

428
00:36:18,719 --> 00:36:21,599
o čem se to piše? Najbrž ljuhu prlo, ne?

429
00:36:22,159 --> 00:36:25,919
Ne, to je Python je večinoma, ne, Python je preprosto data science

430
00:36:25,919 --> 00:36:30,719
jezik, ne, javanci ga ne marate, to mi je men jasno, ne, in tudi neke

431
00:36:30,719 --> 00:36:34,559
vzajemne ljubezne med Pythoniste in vami pač ni, to je znano.

432
00:36:35,520 --> 00:36:38,880
Tako da mi moramo paziti, kako programeri razporedimo,

433
00:36:38,880 --> 00:36:44,239
in da ni fajta. Ampak je pa res, da Python je za te stvari priročen,

434
00:36:44,239 --> 00:36:48,559
ni za enterprise software pisati, ampak za te stvari je pa zelo priročen

435
00:36:48,559 --> 00:36:53,200
in velika večina ogrodi, ki jih pri tem uporabljamo, so napisane

436
00:36:53,200 --> 00:37:00,159
v Pythonu. Ampak ljepilo, Python kot ljepilo, vzadi imamo v tem

437
00:37:00,239 --> 00:37:03,919
MC, verjetno, za te ultraoptimizirane zadeve.

438
00:37:04,880 --> 00:37:09,599
Ja, seveda, da kakšne knjižnice, ki jih Python potem uporablja,

439
00:37:09,599 --> 00:37:15,679
naredi samo vojnico okrog zelo hitre, recimo zelo hitrega nekega

440
00:37:15,679 --> 00:37:20,960
kora, to zagotovo, ja. In če gremo v ta paralelizem na en vidi,

441
00:37:20,960 --> 00:37:27,039
pardon, na GPU, v kateremkoli arhitekturi, je seveda tudi ni Python, ne.

442
00:37:27,119 --> 00:37:31,599
A se morate dost hecati, da v bistvu, ne vem, če imate vego, da, ne vem,

443
00:37:31,599 --> 00:37:35,599
pa stvari tudi tam gor tečeva, je to pač več ali manj tako velik efort?

444
00:37:35,599 --> 00:37:41,039
Ne, trivialno sigurno ni, ne, ker se more, zdaj danes večina mladih

445
00:37:41,039 --> 00:37:48,000
že kar dobro spozna na Docker in na te stvari, ampak tam na sluram

446
00:37:48,000 --> 00:37:52,239
kot recimo menedžer za džobe v takih velikih sistemih, to pa mrzdo

447
00:37:52,239 --> 00:37:56,640
prvič sliše, ko mu povemo, ne, ali pa recimo singulariti in podobne

448
00:37:56,640 --> 00:38:01,440
stvari, ki se na takih HPC sistemih uporabljajo, ampak ta učna krivulja

449
00:38:01,440 --> 00:38:05,440
pa ni tako zelo dolga, ne. Potrebno je napisati ustrezne skripte,

450
00:38:05,440 --> 00:38:10,239
ki potem dajo džob v vrsto in ga lahko spremljajo. Vse moramo tako

451
00:38:10,239 --> 00:38:13,840
narediti, da ne rabimo pač neke interakcije, da lahko teče usporedno,

452
00:38:13,840 --> 00:38:19,599
pa tudi, ker modele, ko učimo, ni nobene garancije, da bo zadeva

453
00:38:19,599 --> 00:38:23,119
se zaključila, lahko v katerenkolikor korak upade, ne, in morajo

454
00:38:23,119 --> 00:38:26,000
biti stvari tako narejene, da lahko potem od tiste točke naprej

455
00:38:26,000 --> 00:38:30,799
štartamo, ne. To ampak neke druge, bi rekel, hude umetnosti ni, ne.

456
00:38:30,799 --> 00:38:37,119
Ampak če mi date človeka, ki še nikoli ni slišal za Linux, ne, in bi želel

457
00:38:37,119 --> 00:38:41,359
biti data scientist in poganjao to na nekih HPC mašinah, pa to ne bo

458
00:38:41,359 --> 00:38:45,359
šlo, ne, ker ne vem niti, kje začeti potem.

459
00:38:48,159 --> 00:38:52,320
Ampak naredite sem tako neko ilustracijo, koliko dolgo pa ti džobi potem

460
00:38:52,320 --> 00:38:54,320
zdrajev na tem superkomputerju?

461
00:38:54,320 --> 00:38:57,280
Ja, zdaj, to je zelo odvisno od tega, kakšen je džob,

462
00:38:57,280 --> 00:38:59,280
od ko ne prej. Seveda, seveda, ampak tako za občutek.

463
00:38:59,280 --> 00:39:03,280
Ja, bom dal par primirov, potem se pa predstavljate sami, ne.

464
00:39:03,280 --> 00:39:10,080
Za finetuning na LLM-ju, tudi če vzajemo ranga, recimo Lama, ne,

465
00:39:10,080 --> 00:39:15,919
tudi večega, recimo desetmiljardnje, ne, ker delamo samo eno epoho,

466
00:39:15,919 --> 00:39:19,119
je to lahko v par dneh, ker je to samo finetuning in ker uporabljamo

467
00:39:19,119 --> 00:39:23,520
tudi pristope, ki ne trenirajo v celega modela, ampak samo

468
00:39:25,280 --> 00:39:29,359
razvilja so se tehnike pač, ki jih lahko, kot so Lora in podobne,

469
00:39:29,359 --> 00:39:33,760
ki jih lahko uporabljamo, da finetuning, specializacijo modela

470
00:39:33,760 --> 00:39:39,200
naredimo hitrej, ne. In to je v roku enega tedna ustrezno

471
00:39:39,200 --> 00:39:44,799
z mogljivih mašinah izvedljivo, ne. Enako velja, bi rekel, za sintezo

472
00:39:44,880 --> 00:39:49,760
in tudi prepoznavo, mislim, da imamo teden do dva tedna dovolj.

473
00:39:51,280 --> 00:39:55,280
Ko govorimo pa o temeljnih jezikovnih modelih, pa mislim, da niti

474
00:39:55,280 --> 00:39:59,119
nimamo hardwarea dovoljno, kot če bi želeli tako velike količine,

475
00:39:59,119 --> 00:40:03,679
kot jih delajo za, recimo, velike jezike, ne, tega pa nimamo dovolj,

476
00:40:03,679 --> 00:40:05,919
je pa prebaljno.

477
00:40:05,919 --> 00:40:14,239
Glede teh odprtokodnih language modelov, kaj v resnici pomeni

478
00:40:14,400 --> 00:40:22,000
odprtokodnost? A govorimo to o odprti uporabi, kaj vidite, da tukaj noter

479
00:40:22,000 --> 00:40:27,280
je zares odprto in kje je potem ta meja, ko pa reče, opa, to pa je naš

480
00:40:27,280 --> 00:40:34,239
nek sikret sos, pa ni. Kje so te meje in kaj te meje, sobi malce

481
00:40:34,239 --> 00:40:35,840
malce o tem še?

482
00:40:35,840 --> 00:40:41,679
Pri modelih je odprtokodnost pomeni večinoma, da imate na voljo

483
00:40:41,760 --> 00:40:47,840
model z vsemi vtežmi, to pomeni pri modelu. Zdaj, postopek, kako je bil

484
00:40:47,840 --> 00:40:52,239
ta model narejen, kaj vse je bilo vključeno, pa ni nujno, da je znano.

485
00:40:52,239 --> 00:40:55,919
Ampak imate pa model z vsemi vtežmi, lahko ga pač ozamete in od njega

486
00:40:55,919 --> 00:41:01,200
naprej gredite, ne, to je odprtokoden model tega tipa. Komercialni niso

487
00:41:01,200 --> 00:41:06,159
tako odprti, če želite vzeti čez GPT, pardon, GPT-3, ga pač ne morete,

488
00:41:06,960 --> 00:41:14,400
LAMA in podobni pa so odprti. Nekateri potem več povejo o postopkih,

489
00:41:14,400 --> 00:41:18,719
drugi pa mnenj. Zdaj, tukaj pa ni mislim, da nekaj pravid.

490
00:41:18,719 --> 00:41:24,640
Ampak, a mislite, da se bo ta del prvi del, da bomo s časom hotli

491
00:41:24,640 --> 00:41:29,359
mogoče celo neko regulativo imeti, ki bo hotla vejeti točnost, ki je

492
00:41:29,359 --> 00:41:34,320
iz kodsoj vzeti te podatki, da bomo tudi ta del treniranja mogli imeti

493
00:41:34,400 --> 00:41:40,479
bolj upisan, definiran, da bo bolj ta sledljivost postala ali to enostavno

494
00:41:40,479 --> 00:41:43,280
tehnično in neizvedljivo?

495
00:41:43,280 --> 00:41:49,760
Jaz ne vem, kam bo jo stvari šle, ker poskušamo vseeno veliko več

496
00:41:49,760 --> 00:41:55,200
večji pomendati etiki na področju uporabe umetne inteligence in potem

497
00:41:55,200 --> 00:42:00,239
se zbojajo, sveda, zelo različni tudi interesi zraben.

498
00:42:01,200 --> 00:42:08,959
Zagotovo pa lahko rečem to, da generativni modeli vam ne morejo

499
00:42:08,959 --> 00:42:14,479
servirati podatkov, iz katerih virov je zdaj nek odgovor prišel razen,

500
00:42:14,479 --> 00:42:19,040
če vam dajo vse vire, ki so bili na voljo. Ker to je statističen

501
00:42:19,040 --> 00:42:23,760
model, najbolj verjetni odgovor pove, in mislim, da se bomo veliko

502
00:42:23,760 --> 00:42:28,400
bolj ukvarjali s tem, da bomo osveščali ljudi, da ti odgovori niso

503
00:42:28,719 --> 00:42:34,640
pravilni, lahko fascinantno zgledajo, ampak se lahko čist napačni,

504
00:42:34,640 --> 00:42:40,160
in pa da bomo se naučili, kje je ta tehnologija zares koristna in kje

505
00:42:40,160 --> 00:42:44,800
je morda ta trenutek še nevarna. To distinkcijo bo treba pač narediti.

506
00:42:44,800 --> 00:42:51,119
Na univerzi smo tudi tako rekli, da je ne, da zapovedujemo ali pa ukazujemo,

507
00:42:51,119 --> 00:42:56,640
ampak priporočamo, da se raziskave dana komisijo etično, ki preveri

508
00:42:56,800 --> 00:43:02,880
raziskavo, kam pelje, ker lahko recimo na koncu z dobljimi nameni

509
00:43:02,880 --> 00:43:09,199
narediš rezultat, ki je zelo škodljiv. Prej, ker sem rekel, da ne moremo

510
00:43:09,199 --> 00:43:13,839
pričakovati, da nam bo servisiral vire, če boste zdaj šli prašati

511
00:43:13,839 --> 00:43:18,239
čez GPT nekaj in bomo napisali vire, je to zato, ker čez GPT ni samo

512
00:43:18,239 --> 00:43:23,439
jezikovni model in bomo tudi verjetno napisali, da skenira brska po

513
00:43:23,439 --> 00:43:26,560
internetu in bo povedal s katerih vire je pogledal. Samo to ni povezano

514
00:43:26,560 --> 00:43:29,839
z jezikovnim modelom, ampak je s istimi viri, ki jih je dejansko vzel,

515
00:43:29,839 --> 00:43:35,040
da je zgeneriral. Pri sami generaciji pa pač ne more biti tako.

516
00:43:35,040 --> 00:43:39,599
Jaz sem mu zdaj dal namenoma za nalogo za en nov projekt, ker vem,

517
00:43:39,599 --> 00:43:43,199
da bo to zelo dobro napisal, in sem mu rekel, napiši mi, zdaj integracija

518
00:43:43,199 --> 00:43:46,719
med AS se pravi razpoznavalnikom govora in jezikovnim modelom.

519
00:43:46,719 --> 00:43:51,599
Napiši mi pač state of the art, napiši mi challenge-e, napiši mi work

520
00:43:51,680 --> 00:43:57,520
package-e, kaj ne bo, je zelo lepo, super. In sem rekel, jaz sej, ampak tudi

521
00:43:57,520 --> 00:44:02,160
reference mi dodej v motivation in je tudi to dodal. In potem grem pogledat,

522
00:44:02,160 --> 00:44:05,199
ker sem vedel, da teh referenc najbolj še ne bom, ampak me je zanimalo,

523
00:44:05,199 --> 00:44:09,199
kaj bom dobil. In sem probov pri treh, pri GBT-u je bil eden,

524
00:44:09,199 --> 00:44:14,800
potem pa še dva druga. In eden sih je čisto izmislil. So bile vseblinsko

525
00:44:14,800 --> 00:44:19,040
ponaslovi, ker je to super bilo, če bih doresto napisal.

526
00:44:19,119 --> 00:44:24,079
Tat drug je pa zanimivo, avtori so bili resnični in članek,

527
00:44:24,079 --> 00:44:28,560
mogoče kakšna beseda je bila drugačna, ampak drugače, celo tak članek

528
00:44:28,560 --> 00:44:33,839
z eno samo drugačno besedo obstajal. In to ni Tewik, ki ga je naredil,

529
00:44:33,839 --> 00:44:38,400
ampak najbolj verjetno je bilo, takega članka ni, ampak najbolj verjetno

530
00:44:38,400 --> 00:44:43,839
bi tja pašal tak člank in je pač bil zgeneriran. In ljudje, jaz mislim,

531
00:44:43,839 --> 00:44:51,520
da povprečen človek se tega ozadja ne razume in zato je zelo pomembno,

532
00:44:51,520 --> 00:44:57,839
da se zavedemo, kaj pač uporabljamo in kje so tudi potencialne nevarnosti.

533
00:44:57,839 --> 00:45:04,560
In zato jaz veliko krati sebi v škodu rečem, da bi morala druga področja,

534
00:45:05,599 --> 00:45:12,400
ne tehnična, v bistvu dobiti mogoče celo več denarja, da pohitrijo svoj tempo,

535
00:45:12,400 --> 00:45:18,079
ker mi dajemo rešitve prehitro na trg. Prehitro pridejo ven in če so tržno

536
00:45:18,079 --> 00:45:22,400
zanimive, se jih ne da več ostaviti, družba pa na njih ni pripravljena.

537
00:45:22,400 --> 00:45:26,959
Ni regulativa ni pripravljena, mogoče niti moralno, etično nismo na to

538
00:45:26,959 --> 00:45:32,160
pripravljeni. Primjer, ki ga vse čas jaz s svojim študentom pravim,

539
00:45:32,160 --> 00:45:38,400
je avtonomno vozilo. Če se avtonomno vozilo znajde v situaciji, ko ima samo dve izbiri,

540
00:45:38,400 --> 00:45:44,640
da na eni strani povozi, ne vem, otroka, na drugi strani babico in ima v svojem

541
00:45:44,640 --> 00:45:48,479
modelju ukodirano, koga bo povozil. A ni to moralno sporno?

542
00:45:49,839 --> 00:45:54,160
Ampak rešitve takšne že so in mi jih poskušamo uvesti na trg.

543
00:45:54,160 --> 00:46:00,319
Zato pravim, da smo v dobih za tehnologijo, ki je za tehnologijo super

544
00:46:00,319 --> 00:46:05,599
in nam se zdi res fascinantno, ko lahko delamo stvari, ki presunujo

545
00:46:05,599 --> 00:46:11,520
na človeštvo, ampak ne vem, če smo sploh pripravljeni jih pametno uvajati.

546
00:46:11,520 --> 00:46:16,479
In kje jaz mislim, da moramo imeti malo premislek.

547
00:46:23,040 --> 00:46:29,040
Mi smo imeli pred enim letom epizodo, ko smo gorili tudi v LLMA-jih

548
00:46:29,040 --> 00:46:34,959
in pa EIU. A mi zdaj tukaj, ko se pogovarjamo,

549
00:46:34,959 --> 00:46:39,119
ali bo to čez šest mesecov, to se mi zdi, da se dori grejo tako hitro naprej,

550
00:46:39,119 --> 00:46:44,239
da ne vem, neke stvari se nam zdijo samo umevne.

551
00:46:44,239 --> 00:46:48,479
OK, ta strateški pomen Slovenščine, to bo pač vstova.

552
00:46:48,479 --> 00:46:53,680
To pač, po moje, ta mesec smo dalj naprej, da je to pač pomembno,

553
00:46:53,680 --> 00:46:58,000
da se moramo s tem ukvarjati, da moramo proaktivni biti, da se to ne pade v nekaj pozabov.

554
00:46:58,479 --> 00:47:03,520
Ampak pač te tehnološke LLM stvari,

555
00:47:03,520 --> 00:47:08,239
ne bom rekel, kje bomo čez tri mesece, ampak ne vem.

556
00:47:08,239 --> 00:47:12,239
Delamo to vse bino, pa pa mogoče bodo, ne vem, čez tri mesece bomo pa rekel,

557
00:47:12,239 --> 00:47:16,239
ja, pa sej, to je tako normalnost.

558
00:47:16,239 --> 00:47:20,800
Zdaj, mislim, da bi manjkali tri pive, da bi na to odgovarjal, a ne?

559
00:47:21,359 --> 00:47:28,079
Kje je napovedovati prihodnost za, ne vem, umetno inteligenco je nekaj,

560
00:47:28,079 --> 00:47:33,839
po moje, skoraj bolj pašo v bar, da se človek sprosti pa malo filozofira, kaj bo.

561
00:47:33,839 --> 00:47:38,479
Jaz osebno, sicer ampak se ne čutim, da bi bil jaz guru na tem področju,

562
00:47:38,479 --> 00:47:43,760
ampak iz vsega, kar razumem in preberem, pa se mi edino to zdi,

563
00:47:43,760 --> 00:47:50,880
da ta trenutek imamo zelo velik rešitev, ki uporabljajo izjemno dobre modele,

564
00:47:50,880 --> 00:47:56,560
naučene na ogromnih količinah podatkov, ampak zato potrebujemo veliko časa,

565
00:47:56,560 --> 00:48:00,719
da jih naučimo in potem jih uporabljamo. In ti modeli običajno niso potem

566
00:48:00,719 --> 00:48:05,760
interaktivno učeni, ne? Ampak jih učimo, pa potem delamo inferenco,

567
00:48:05,760 --> 00:48:11,199
pa učimo in tako naprej. In to se pa utegne, ta cikl se utegne

568
00:48:11,199 --> 00:48:17,280
z zelo hitrim razvojem hardvera, se zna tako zmanjšati,

569
00:48:17,280 --> 00:48:23,199
da bo na nekaterih področjih možno to početi v realnem času.

570
00:48:23,199 --> 00:48:28,560
In to pa je, moja potenc, pet prostor, še že kakšen dodaten

571
00:48:28,560 --> 00:48:34,560
dolg korak naprej, kaj se bo to zgodilo. In že to, da smo mi nekaj let nazaj

572
00:48:34,560 --> 00:48:40,319
postavljali vego v Mariboru, ki je tako velika, tudi prostorsko,

573
00:48:40,319 --> 00:48:46,880
in da je to zdaj v eni omari, že to pač ne kazuje, da je tukaj

574
00:48:46,880 --> 00:48:51,920
še očitno veliko prostora in ko bo enkrat to možno, da sistem

575
00:48:51,920 --> 00:48:58,880
se v realnem času uči, to pa mislim, da še kakšno mejo potem premakne.

576
00:48:58,880 --> 00:49:05,359
Eno vprašanje še mogoče je tudi povezano s tem. Govorimo v eno milijardo

577
00:49:05,359 --> 00:49:10,319
tokenov, 10 milijard tokenov, LAMA mislim, da ima 70 milijarda.

578
00:49:10,319 --> 00:49:17,199
A je to, bomo prišli do tega, ko dodajenje teh tokenov ima nekaj

579
00:49:17,199 --> 00:49:22,400
kap, je ta krivulja, se bo, a moramo zdaj dodati tisoč milijard,

580
00:49:22,400 --> 00:49:27,520
ali se bo to nekje ostavilo in bo treba začeti, ne boš mogel več

581
00:49:27,520 --> 00:49:32,079
tako denarja vršiti ta problem, pa tako tokenov, bomo mogli tudi bolj

582
00:49:32,160 --> 00:49:37,680
algoritme spremeniti ali cel ta fundamentalni lejer. A vidite to nekje

583
00:49:37,680 --> 00:49:43,439
trende, da obstaja neka zgorna meja, kjer je to smiselno delati?

584
00:49:43,439 --> 00:49:49,040
Skoraj postate zgorna meja. Tako kot si zastavil vprašanje, je meja

585
00:49:49,040 --> 00:49:54,640
že recimo poslovno gledano ali pa recimo smiselne stoji tega početja.

586
00:49:54,640 --> 00:50:00,079
Ampak jaz mislim, da tudi vsebinsko in tehnično je ta meja zato, ker

587
00:50:00,000 --> 00:50:04,200
To, kar mi potrebujemo, je se zarez zelo dobro naučiti vseh

588
00:50:05,400 --> 00:50:08,480
znanih in skritih značilnosti jezika.

589
00:50:09,080 --> 00:50:13,480
In osebno sem pripričan, da je nekje meja,

590
00:50:13,520 --> 00:50:17,639
kjer ne potrebujemo iti več naprej, ker bomo pač to zarez

591
00:50:18,040 --> 00:50:19,959
vse te featureje nekako zajeli.

592
00:50:21,360 --> 00:50:26,080
Ampak jezik je zelo velik, način izražanja zelo pester,

593
00:50:26,879 --> 00:50:33,400
osebine je tudi ogromno in je ta meja potencijalno zelo visoka.

594
00:50:35,080 --> 00:50:39,680
Andraž, ne bom rekel, da je čas za pivo, mogoče čas za kosilo,

595
00:50:39,840 --> 00:50:41,639
tako da, boš še zadnje vprašanje?

596
00:50:43,439 --> 00:50:44,439
Ja.

597
00:50:47,439 --> 00:50:50,160
Kajče, a si upamo zbrati eno vprašanje iz publike?

598
00:50:50,880 --> 00:50:51,880
Lahko.

599
00:50:51,919 --> 00:50:54,080
Da gremo malo out of the comfort zone.

600
00:50:55,080 --> 00:50:57,080
Kdo bo dvih narokel? Kdo upa?

601
00:51:01,080 --> 00:51:02,680
Ekskluzivna priložnost.

602
00:51:05,080 --> 00:51:09,040
A se med projekti, ki so bolj tehnične narabe, najde tudi vprašanje,

603
00:51:09,080 --> 00:51:14,519
ki se govarja bolj z ta projekt, ki bi pozaveščal javnost

604
00:51:14,559 --> 00:51:19,519
o mogoče lajičnem razumevanju teh modelov,

605
00:51:20,519 --> 00:51:23,959
kaj je točno, kaj ste rekel, da bi bil problem neke aplikacije,

606
00:51:24,000 --> 00:51:25,959
nekje digitalnih modelev, nekaj zdaj.

607
00:51:26,519 --> 00:51:29,959
Imamo nek lajk uprečen Slovenec, ki je povidel, če je tip,

608
00:51:30,000 --> 00:51:32,959
ki je povidel neko novo, a jo urodi, bo rekel, oto, pa je zdaj to.

609
00:51:33,519 --> 00:51:36,480
Ampak v dodanju se pa skriva točno to, saj tistečen model,

610
00:51:36,519 --> 00:51:38,959
ki predvidi naslednjo najbolj porednost.

611
00:51:39,519 --> 00:51:42,480
A se kaj dela na tem, da bi ministerstvo digitalno,

612
00:51:42,519 --> 00:51:47,959
ali pa toliko in drugo, imel projekte, ki javno ozaveščajo

613
00:51:48,959 --> 00:51:50,400
o teh materijskih tehnologijah?

614
00:51:50,959 --> 00:51:53,400
Zdaj bom imel samo ponovno vprašanje, da gre v ETR.

615
00:51:54,959 --> 00:51:58,400
To se pravi, obstaja kakšen projekt, ki bi lajično javnost

616
00:51:58,959 --> 00:52:03,400
izobraževal v bistvu o teh tehnologijah, za to, da bi plač širša javnost

617
00:52:03,959 --> 00:52:07,400
bolj prepravljena na sprejem teh tehnologij?

618
00:52:07,959 --> 00:52:11,399
Zelo kaj nakratko, samo tako, da bodo poslušalci slišali.

619
00:52:11,960 --> 00:52:16,399
Mar si kaj, vse dogaja. Tudi jaz sem videl že kar nekaj,

620
00:52:16,399 --> 00:52:22,839
je bilo razpisov, kjer so sovkvarjali z velikem jezikovnim modeljem

621
00:52:23,399 --> 00:52:27,839
izne tehničnega aspekta, tako da predvidevam, da tam pokrivajo

622
00:52:28,399 --> 00:52:34,839
tudi take vidike. Mi na naši fakulteti poskušamo se predvsem uključevati

623
00:52:35,399 --> 00:52:39,839
v skupine, ki so interdisciplinarne, zato ker se nekako zavedamo,

624
00:52:40,399 --> 00:52:45,839
da mi smo le tehniki in za, recimo, mi lahko razložimo, kako to deluje.

625
00:52:46,399 --> 00:52:50,839
Ampak kakšen vpliv to ima na družbo, na mlade, na ne vem kaj,

626
00:52:51,399 --> 00:52:56,839
to pa ni naše področje, ki bi ga zares lahko dobro razumeli,

627
00:52:57,399 --> 00:53:02,839
ker se z njim ne ukvarjamo in tu iščemo druge. In kot sem prevel menil,

628
00:53:03,399 --> 00:53:06,839
etična komisija na univerziji je tako postavljena, ampak na začetku

629
00:53:07,399 --> 00:53:10,839
je bila brez nas, brez tehnikov. Mi smo zdaj izraven, zato da saj

630
00:53:10,839 --> 00:53:16,279
povemo, kaj te stvari so, ker to pa smo že veliko krati videli,

631
00:53:16,839 --> 00:53:21,279
da je veliko ljudi, ki je prepričani, da ve kaj to je, pa ne ve.

632
00:53:21,839 --> 00:53:27,279
Tako da ta del poskušamo še narediti. Ministrstvo ne smem kritizirati,

633
00:53:27,839 --> 00:53:33,279
ampak želel bi si pa sveda malo več tudi proaktivnost iz njihove stranine.

634
00:53:34,839 --> 00:53:40,279
Zdaj imamo še zadnje vprašanje. Mi imamo to privilegij, da nas poslušajo

635
00:53:40,839 --> 00:53:46,279
slovenski govoreči, odjem slovenski govoreči, razvijalci najširjšega

636
00:53:46,839 --> 00:53:53,279
spektra znanj in podobno. Imate za nekako preložnost jih pozvat,

637
00:53:53,839 --> 00:53:59,279
da se tam nekaj pomagajo ali kakorkoli, rabite to pomoči komuniti,

638
00:53:59,839 --> 00:54:04,279
in če rabite, na kak način, kako bomo lahko nekako pomagali

639
00:54:04,839 --> 00:54:07,279
pri vsem tem efortu?

640
00:54:08,279 --> 00:54:11,720
Če že kaj lahko apeliram, samo da v svojih okoljih,

641
00:54:12,279 --> 00:54:16,720
ker tukaj vseeno ne gre za nekaj privat stvari, ki bi nekdo delil

642
00:54:17,279 --> 00:54:21,720
z nami, ampak gre za, ne vem, da dobimo gradivo iz NTK,

643
00:54:22,279 --> 00:54:26,720
torej iz naše nacionalne knjižnice ali pa dobimo iz RTV ali pa dobimo

644
00:54:27,279 --> 00:54:31,720
iz Sodič in podobno. Tukaj jaz mislim, da je potrebno zgolj razumevanje,

645
00:54:32,720 --> 00:54:38,160
da je Slovenščina v nasplotnem primjeru na slabi poti,

646
00:54:38,720 --> 00:54:44,160
kje bo pač ostala. Jaz kar nekaj delam z recimo zdravniki,

647
00:54:44,720 --> 00:54:49,160
zaradi te razpoznave govora in tako, in oni rečejo,

648
00:54:49,720 --> 00:54:53,160
ja, jaz sem bil v Ameriki, tam gre zdravnik na vizito

649
00:54:53,720 --> 00:54:57,160
in ko pride nazaj, ima že zapisnik, kaj se je pogovarjal s pacijentom.

650
00:54:57,720 --> 00:55:01,160
Jaz razumem, ampak mi ne moramo pomagati, se ne moramo niti dobiti,

651
00:55:01,720 --> 00:55:05,160
srečetke pogovora med pacijentom in zdravnikom, ampak tukaj

652
00:55:05,720 --> 00:55:10,160
rabimo potem leta, da pravno pridemo skozi. Edina ta način, da malo bolj

653
00:55:10,720 --> 00:55:14,160
razumemo, kaj vse je treba narediti in kje je treba mogoče

654
00:55:14,720 --> 00:55:18,160
kakšno zavorost prostiti, da bomo lahko pač tudi sami to naredili,

655
00:55:18,720 --> 00:55:22,160
ker gači pač preprosto to ne gre. Že pa sem vam prej pravil,

656
00:55:22,720 --> 00:55:26,160
mi smo sestavili tisoč ur za razpoznavo govora. Najboljši modeli

657
00:55:26,720 --> 00:55:30,160
so učeni na 500 tisoč urah. Kaj se zlikaj to?

658
00:55:32,720 --> 00:55:35,160
Ok, sklep na misel, Draž.

659
00:55:35,720 --> 00:55:41,160
Ja, ne vem, če sem jaz, da bom to lepo vzel. Dejte povedati svojim

660
00:55:41,720 --> 00:55:45,160
kolegom malo te problematiki, da se ta besedica malo razširi.

661
00:55:46,720 --> 00:55:50,160
Drugače pa, ja, jaz bi se zahvalil vsem za vašo pozornost,

662
00:55:50,720 --> 00:55:56,160
kot le v publiki, kot kar vsi tisti, ki nas poslušate v avtu

663
00:55:56,160 --> 00:56:01,600
kjerkoli. Ja, zato, ker se mi zdi, da pač pozornost je zdaj res neka

664
00:56:02,160 --> 00:56:06,600
taka redka dobrina, za katero smo vam zelo hvaležni.

665
00:56:09,160 --> 00:56:13,600
Hvala lepa vsem za prisotnost in obiljo vprašanj.

666
00:56:22,160 --> 00:56:25,600
Hvala tudi iz moje sprospektive, hvala ekipi, hvala podpornih

667
00:56:26,160 --> 00:56:29,600
vznikov in hvala, da ste bili z nami. Do naslednjič. Srečno.